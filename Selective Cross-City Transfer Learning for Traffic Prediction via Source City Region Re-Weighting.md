## 师兄推荐的：Selective Cross-City Transfer Learning for Traffic Prediction via Source City Region Re-Weighting  
1. 推荐理由：==跨城市交通==可能会是一个特殊点，一个比较少的竞争方向
2. 摘要部分：  
	* 目的是为了解决数据不足的问题（少部分城市有大量数据，其他没有）  
	* 方法是迁移学习，但是迁移学习有缺点：
		* 有可能在源城市学习的模型对于目标城市有不好的信息  
	* 提出的模型CroeeTRes，解决了这个问题：  
		1. 特征网络 使用领域适应技术，使用边和节点级的数据学习源和目标的空间特征  
		2. 权重网络 使用源-目标联合元学习去给对于目标城市微调有用的区域赋予高权重  
		3. 预测网络 使用学到的区域权重选择性在源城市上训练实现微调  
3. 引言：  
	* 从自然语言处理学习到了区域迁移学习，但是有问题：
		* 全局的区域特征难以抽取，NLP有共同的词集，跨城市没有相交的区域  
		* 评价源区域的有用程度分数，没有相交的区域，不好评价有用性  
4. 相关工作：  
	* 目前的工作都是关注如何 fine tuning，但是没有关注如何训练一个源模型，本文解决这样的问题，选择性的学习  
	* 选择性学习先例以及可行的原因：  
		* CV领域有预训练CNN，NLP有词嵌入，可概括的特征  
		* 领域之间有明显的连接，比如相同的词集  
		* 城市之间都没有  
	* 区域特征学习目前都集中单城市上  
5. 背景与动机：  
	1. 前言：  
		* 符号与定义：  
			* 区域： 城市用经纬度范围进行栅格化，每一个栅格就是区域，区域集合用C表示  
			* 时间间隔： 城市时间间隔划分为等长不相交的间隔1，……Tc。
			* 区域交通数据： 每个C中的区域分一个向量表示数据
			* 目前是栅格，以后改进为基于图
			* 于是训练的目标可以如下表示： ![训练目标 公式](https://github.com/Liwu-di/papers-read/blob/main/pic/1.png) 
			* fine tuning:  
				* 第一步：源训练，有两种方式：  
					* 监督学习  
					* 元学习  
				* 第二步：使用目标数据微调  
	2. 动机与问题定义：  
		* 迁移学习希望缩小在目标数据集的误差，但是训练源模型的时候是在目标数据集学习，会有噪声和错误信息， 提出的模型在源训练时迁移，使用区域级选择  
		* 选择性迁移学习的目标是学习区域权重，然后再微调，如下公式![源区域权重 公式](https://github.com/Liwu-di/papers-read/blob/main/pic/2.png)  
		* 一方面提高了效果，另一方面，可视化  
6. 方法：  
	1. 整体架构  
		* 特征网络  
		* 权重网络  
		* 预测网络  
		* 结构图：![结构图 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/3.png)  
	2. 模型组件  
	3. how to learn Theta-f,w以及Theta, lambda-rs  
	4. 一些思考如图：  
		* ![思考手写图片 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/4.jpg)  
		* ![思考手写图片 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/5.jpg)  
		* ![思考手写图片 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/6.jpg)  
	5. 伪代码：  
		* ![思考手写图片 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/7.png)
7. 实验及结论  
	1. 数据集：  
		* 出租车和自行车，纽约，芝加哥，华盛顿  
		* 预测模型[ST-NET](https://dl.acm.org/doi/abs/10.1145/3308558.3313577?casa_token=BYrLv2Lrd8EAAAAA%3Al-TmLjK_I2lc8ItaWoF5G_fUPzKyhm4lePfUlAT7QXqvFsyAtyX3anJRLrbMZEonuklk9O9upaGhHIk)，特征网络[MVURE](http://fi.ee.tsinghua.edu.cn/public/publications/301ad6d8-92b8-11eb-96bc-0242ac120003.pdf)  
	2. 结果  
		* ST-NET 少数据时退化严重  
		* CrossTReS 始终很好，比最好的优秀8%  
		* 图如下：![experiment result](https://github.com/Liwu-di/papers-read/blob/main/pic/8.png)  
	3. 模型分析：  
		1. 空间特征的领域适应：  
			1. 任务：  
				* 地区分类。我们进行区域分类实验以显示学习区域特征的质量。我们根据数据集中上下车的总数标记每个城市的区域。每个城市中前 25%、50% 上客和下客的区域标记为 0、1 等。我们将两个城市的 ΦS、ΦT 混合，并使用逻辑回归报告 5 倍交叉验证分数。  
				* 目标绩效。我们遵循 Sec 中的评估协议。 5.2.1 并报告目标城市 (DC) 的绩效。  
			2. 模型：  
				* CrossTReS-POI：我们不学习空间特征，而是使用 POI 向量（详见附录 C 节）作为加权网络的输入；  
				* CrossTReS-NoDA：我们设置𝛽1 = 𝛽2 = 0 以消除域适应。在这种情况下，ΦS、ΦT 可能遵循不同的分布，这可能会影响区域重新加权。  
				* CrossTReS：具有𝛽1 = 𝛽2 = 2 的完整CrossTReS。  
				* CrossTReS-GRL：我们沿共享边缘分类器𝐹𝜃𝑒𝑑𝑔𝑒添加一个具有梯度反转层（GRL）的对抗域鉴别器。
			3. 结果：  
				* 与 CrossTReS-POI相比，学习空间特征的变体在区域分类和目标流量预测方面都更加精确。这表明特征网络学习了指示性空间特征，从而导致更有效的选择性迁移学习。  
				* 与CrossTReS-NoDA 相比，CrossTReS在两个实验中都取得了更好的表现，这表明通过域适应学习可概括的区域特征，我们可以更好地识别城市间功能相似的区域，以帮助选择性迁移学习。  
				* 比较CrossTReS和CrossTReS-GRL，我们观察到非常相似的性能，表明共享边缘分类器很好地执行了边缘级域自适应，并且不需要额外的域鉴别器。  
				* 如图：![结果图 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/9.png)  
				* 超参数beta的选择影响：![结果图 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/10.png)  
		2 权重网络的影响：  
			* 方法：  
				* 我们移除加权网络𝜃𝑤，并直接使用ΦS、ΦT 通过Eqn 计算𝜆𝑟S。  
				* 我们改变内部循环（方程 12 和 13）中源和目标更新的数量𝐾S、𝐾T 以分析它们的影响。  
			* 结论：  
				* 没有加权网络𝜃𝑤，性能略有下降，表明加权网络有助于进一步捕获用于选择性源训练的指示性特征。  
				* 最好的结果是在 𝐾T = 1 时获得的，这表明通过额外的微调模拟，可以更好地识别对目标微调有用的源知识。  
				* 结果图： ![结果图 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/11.png)  
		3. 案例分析 𝜆𝑟S  ：
			* 任务1：平均值和稀疏性。我们分析了源训练期间𝜆𝑟S 的两个属性的趋势：平均值和稀疏性。我们独立进行了 6 次实验  
				* 平均值，即 S 上的𝜆𝑟S的平均值 ；   
				* 稀疏性，即具有低权重的源区域的比率𝜆𝑟S < 𝜀；我们设置𝜀 = 0.25。  
			* 结论：  
				* 源区域的平均权重随着源训练的进行而逐渐下降，这表明在源训练过程中，模型逐渐学习到与目标城市无关的源知识，导致权重下降。  
				* 随着源训练的进行，𝜆𝑟S 的稀疏性逐渐增加。此外，我们在源训练结束时观察到高度稀疏性（60-80% 的区域有𝜆𝑟S < 0.25）。这两个事实都表明，CrossTReS 通过分配低权重逐渐学会排除不相关的源区域。  
				* 两个指标在不同的运行中显示出相似的趋势，表明 CrossTReS 可以稳定地选择有用的源区域。
				* 结果图： ![结果图 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/12.png)  
			* 任务2： 𝜆𝑟S可视化  
				* 我们可视化学习的权重来说明 CrossTReS 的选择。如图所示，曼哈顿的权重比新泽西、布鲁克林、布朗克斯和皇后区高得多。这种现象可以用两种方式来解释。一方面，与华盛顿特区相似，曼哈顿拥有许多旅游景点，这导致热门目的地的相似性。另一方面，华盛顿特区经济发达，而曼哈顿是纽约州经济最发达的县2。因此我们得出结论，CrossTReS 的选择很好地对应了跨城市区域相似性的各种概念  
				* 结果图： ![结果图 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/13.png)  
8. 附录  
	1. 数据处理：  
		* 简介：我们从纽约 3 、芝加哥 4 和华盛顿特区 5 收集自行车和出租车数据。我们在表 2 中显示了所选数据集的确切空间范围。所有数据集都包含出租车/自行车旅行，包括接送时间和地理坐标。我们相应地将它们处理成数组，记录每个时间间隔内的接送次数。此外，芝加哥的出租车数据集和华盛顿特区涉及地理和时间四舍五入，即确切时间四舍五入到最接近的 15/30分钟，确切位置四舍五入到人口普查区域的中心。在这些情况下，我们会遵循数据提供的大致时间和位置信息。未记录任何上车/下车的区域将不包括在计算错误中。  
		* 多图介绍：对于多视图城市数据，除了通过自行车和出租车旅行提取的人类流动性外，我们还从 OpenStreetMap6 收集道路信息和 POI 属性。对于道路信息，我们将其处理成图 G C 𝑟𝑜𝑎𝑑。两个区域 (𝑟1, 𝑟2) ∈ GC 𝑟𝑜𝑎𝑑，如果它们通过高速公路连接。对于 POI 信息，我们将其处理为矩阵 PC ∈ R |C |×14 。 p𝑟 ∈ R 14 表示区域 𝑟 ∈ C 中每个类的 POI 数。我们考虑以下 POI 类：
			* 0：风景名胜区  
            * 1：医疗卫生服务  
            * 2：家政服务  
            * 3：住宅区  
            * 4：金融机构（例如银行）  
            * 5：体育和休闲服务  
            * 6：文化和教育服务  
            * 7：购物  
            * 8：住房服务（例如酒店）  
            * 9：政府和组织  
            * 10：公司  
            * 11：餐饮  
            * 12：交通  
            * 13：公共服务  
		* 多视图城市图形构建  
			* 接近度 GC 𝑝𝑟𝑜𝑥。我们将每个区域 𝑟 与以 𝑟 为中心的 3×3 网格内的 8 个区域链接起来。边界上的区域将链接到少于 8 个区域。  
			* 道路连接 G C 𝑟𝑜𝑎𝑑。与高速公路相连的区域与无向边相连。  
			* POI: GC 𝑝𝑜𝑖。具有相似 POI分布的区域表明相似的城市功能。因此，给定区域𝑟，我们将其与具有最高 𝑘 个余弦相似度的区域连接 
				* POISim(𝑟, 𝑟′ ) = CosSim(p𝑟, p𝑟′), 𝑟, 𝑟′ ∈ C 其中 p𝑟 是𝑟的 POI 向量p𝑟,𝑖表示区域𝑟中类别𝑖的POI的数量  
			* 人类流动性 GC 𝑠 ， GC 𝑑：人类流动模式揭示了区域功能。例如，住宅区和商业区之间的旅行应该比住宅区之间的旅行更频繁。为此，给定来自人类流动性的起点-目的地 (OD) 对 MC = {(𝑟𝑠 , 𝑟𝑑 )}，我们计算区域 𝑟, 𝑟′∈ C之间的权重为 𝑤(𝑟,𝑟′) = |{(𝑟𝑠,𝑟𝑑)∈MC|𝑟𝑠=𝑟,𝑟𝑑=𝑟′}|，并进一步计算区域𝑟的源和目的地分布，将其移动模式建模为：最后，我们将每个区域𝑟与源分布s(·|𝑟)中具有最高𝑘相似性（KL散度）的区域连接起来，形成 GC 𝑠 ，类似地 GC 𝑑。  
				* 公式： ![公式图 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/14.png)  
	2. 实验细节  
	3. 超参数设置  
	4. 附加实验（速度预测）  
	5. 未来工作  
		* 我们通过使用来自香港的出租车数据进行实验来讨论未来的工作。该数据集包含6个月的数据。我们以香港为目标城市，训练数据为7天。香港数据集与论文中数据集的一个主要区别是香港的POI数据高度稀疏，对区域特征产生负面影响学习。因此，CrossTReS 仅略微优于基线（最多达∼3%）。因此，我们认为在未来的工作中处理缺失和低质量的数据视图很重要。  
9. 补充知识-元学习([参考自知乎](https://zhuanlan.zhihu.com/p/136975128))  
	* 介绍：通常在机器学习里，我们会使用某个场景的大量数据来训练模型；然而当场景发生改变，模型就需要重新训练。但是对于人类而言，一个小朋友成长过程中会见过许多物体的照片，某一天，当Ta（第一次）仅仅看了几张狗的照片，就可以很好地对狗和其他物体进行区分。元学习Meta-Learning，含义为学会学习，即learn-to-learn，就是带着这种对人类这种“学习能力”的期望诞生的。Meta-Learning希望使得模型获取一种“学会学习”的能力，使其可以在获取已有“知识”的基础上快速学习新的任务，如：  
		* 让Alphago迅速学会下象棋  
		* 让一个猫咪图片分类器，迅速具有分类其他物体的能力  
		* 需要注意的是，虽然同样有“预训练”的意思在里面，但是元学习的内核区别于迁移学习  
		* ![参考图 图片](https://github.com/Liwu-di/papers-read/blob/main/pic/15.jpg)  
		* 在机器学习中，训练单位是一条数据，通过数据来对模型进行优化；数据可以分为训练集、测试集和验证集。在元学习中，训练单位分层级了，第一层训练单位是任务，也就是说，元学习中要准备许多任务来进行学习，第二层训练单位才是每个任务对应的数据。二者的目的都是找一个Function，只是两个Function的功能不同，要做的事情不一样。机器学习中的Function直接作用于特征和标签，去寻找特征与标签之间的关联；而元学习中的Function是用于寻找新的f，新的f才会应用于具体的任务。  
		* 其余的内容参考知乎，就不搬运了
10. 代码： 
	* [github](https://github.com/Liwu-di/CrossTReS)  
	